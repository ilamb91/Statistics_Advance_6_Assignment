{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fa32ddd-92b4-488f-8847-9f8e52f3f35e",
   "metadata": {},
   "source": [
    "# Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact the validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f02abe3-6327-4451-a1c7-9e53931f53b1",
   "metadata": {},
   "source": [
    "Analysis of Variance (ANOVA) is a statistical technique used to compare the means of three or more groups to determine if there are significant differences among them. To use ANOVA effectively and interpret its results accurately, certain assumptions must be met. Violations of these assumptions can impact the validity of the ANOVA results. The main assumptions for ANOVA are:\n",
    "\n",
    "- Independence of Observations:\n",
    "\n",
    "Assumption: Observations within each group must be independent of each other, meaning that the values in one group should not depend on or be influenced by the values in another group.\n",
    "\n",
    "Violation Example: In a study comparing test scores of students from different schools, if students from the same school collaborate or share answers, the independence assumption is violated.\n",
    "Normality:\n",
    "\n",
    "Assumption: The data within each group should follow a normal distribution. This assumption is more critical for smaller sample sizes (typically less than 30 per group).\n",
    "\n",
    "Violation Example: If a group's data is significantly skewed or has heavy tails, it may not meet the normality assumption. For example, test scores in a highly competitive exam may have a skewed distribution.\n",
    "\n",
    "- Homogeneity of Variance (Homoscedasticity):\n",
    "\n",
    "Assumption: The variances of the groups should be roughly equal. In other words, the spread of data points within each group should be similar.\n",
    "\n",
    "Violation Example: If one group has much larger variance (greater variability) than another, it can violate the homogeneity of variance assumption. \n",
    "\n",
    "For instance, if one group of employees has highly variable productivity compared to another group, this assumption may be violated.\n",
    "Examples of Violations and Their Impact on Validity:\n",
    "\n",
    "- a. Non-Normality:\n",
    "\n",
    "Violation: Suppose you are comparing the effectiveness of three different medications on pain relief, and the data for one medication group is heavily skewed due to a few extreme outliers.\n",
    "\n",
    "Impact: The ANOVA results may be invalid. A non-normal distribution can affect the accuracy of p-values and confidence intervals, leading to incorrect conclusions.\n",
    "\n",
    "- b. Heteroscedasticity:\n",
    "\n",
    "Violation: In a study comparing the performance of three car models, if the variances of the miles per gallon (MPG) for each model are significantly different, with one model having much larger variance.\n",
    "\n",
    "Impact: ANOVA assumes equal variances among groups. Heteroscedasticity can lead to inflated Type I error rates (false positives) or reduced power, making it harder to detect true differences.\n",
    "\n",
    "- c. Lack of Independence:\n",
    "\n",
    "Violation: In a survey of employee satisfaction, responses from employees within the same department may not be independent if they influence each other's responses.\n",
    "\n",
    "Impact: Violations of independence can lead to unreliable ANOVA results. It may also affect the representativeness of the sample.\n",
    "\n",
    "When these assumptions are violated, alternative statistical methods or transformations of the data may be necessary to address the issues and ensure valid conclusions. Additionally, if the assumptions cannot be met, caution should be exercised when interpreting ANOVA results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b9d658-8931-4c04-8cfd-290429082751",
   "metadata": {},
   "source": [
    "# Q2. What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caa8cf2-e613-4339-bb44-ff941b5e9bd0",
   "metadata": {},
   "source": [
    "Analysis of Variance (ANOVA) is a statistical technique used to compare the means of three or more groups to determine if there are significant differences among them. There are three main types of ANOVA, each suited for different situations:\n",
    "\n",
    "- One-Way ANOVA:\n",
    "\n",
    "Use Case: One-way ANOVA is used when you have one categorical independent variable (factor) with three or more levels or groups and a continuous dependent variable. It is employed to test if there are any statistically significant differences in the means of the groups.\n",
    "\n",
    "_Example: Comparing the test scores of students who attended three different schools to determine if there are significant differences in their performance._\n",
    "\n",
    "- Two-Way ANOVA:\n",
    "\n",
    "Use Case: Two-way ANOVA is used when you have two categorical independent variables (factors) and a continuous dependent variable. It assesses the impact of both factors on the dependent variable and whether there are interactions between the factors.\n",
    "\n",
    "_Example: Evaluating the effects of two factors, such as the type of fertilizer (Factor A) and the amount of sunlight (Factor B), on plant growth._\n",
    "\n",
    "- Repeated Measures ANOVA (or Within-Subjects ANOVA):\n",
    "\n",
    "Use Case: Repeated Measures ANOVA is used when you have a single group of subjects that is measured at multiple time points or under different conditions (repeated measurements) and a continuous dependent variable. It is used to assess changes within the same subjects over time or across conditions.\n",
    "\n",
    "_Example: Examining the effect of a drug treatment on the blood pressure of the same group of patients before treatment, immediately after treatment, and at regular intervals thereafter._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8680bbb6-25ad-4904-9b4a-199fbb578d10",
   "metadata": {},
   "source": [
    "# Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49f1b2f-c53c-4604-8a7d-784db8c9be74",
   "metadata": {},
   "source": [
    "The partitioning of variance in Analysis of Variance (ANOVA) is a fundamental concept that helps explain the sources of variability in a dataset and how they contribute to the overall variance in the dependent variable. It is important to understand this concept because it provides valuable insights into the relationships between factors, helps assess the significance of those relationships, and guides the interpretation of ANOVA results. Here's an explanation of the partitioning of variance in ANOVA:\n",
    "\n",
    "In ANOVA, the total variance in the dependent variable is divided into two main components:\n",
    "\n",
    "- Between-Group Variance (or Treatment Variance):\n",
    "\n",
    "This component represents the variability in the dependent variable that is attributed to the differences between the groups or levels of the independent variable(s). It measures how much the group means differ from each other.\n",
    "Mathematically, it is calculated as the sum of squared differences between the group means and the overall mean, weighted by the number of observations in each group.\n",
    "\n",
    "- Within-Group Variance (or Error Variance):\n",
    "\n",
    "This component represents the variability in the dependent variable that cannot be explained by the differences between the groups. It includes random variability and unexplained sources of variance within each group.\n",
    "Mathematically, it is calculated as the sum of squared differences between each individual data point and the mean of its respective group.\n",
    "The key idea behind partitioning the variance is to assess whether the between-group variance is significantly greater than the within-group variance. If the between-group variance is much larger than the within-group variance, it suggests that there are significant differences among the groups, and this is typically what ANOVA tests for.\n",
    "\n",
    "The ratio of between-group variance to within-group variance, known as the F-statistic, is used to determine whether the differences among group means are statistically significant. If the F-statistic is sufficiently large, it suggests that at least one group is different from the others, and you can reject the null hypothesis, concluding that there are significant differences among the groups.\n",
    "\n",
    "- Understanding the partitioning of variance is important for several reasons:\n",
    "\n",
    "Interpretation of Results: It helps you interpret ANOVA results by quantifying the relative importance of the factors being studied in explaining the variability in the dependent variable.\n",
    "\n",
    "Identifying Significant Effects: It allows you to identify which factors or levels of factors have a significant effect on the dependent variable, helping you focus on meaningful relationships in your data.\n",
    "\n",
    "Model Assessment: It aids in evaluating the goodness of fit of your statistical model, indicating whether the model adequately explains the observed variation in the data.\n",
    "\n",
    "Research and Decision Making: It assists researchers, analysts, and decision-makers in drawing conclusions about the impact of different factors or treatments on the dependent variable, which can inform further investigations or decisions.\n",
    "\n",
    "In summary, understanding the partitioning of variance in ANOVA is crucial for conducting hypothesis tests, drawing meaningful conclusions, and making informed decisions based on the analysis of data with multiple groups or factors. It helps identify where the variability in the data comes from and whether it is statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8e8a1a-b61b-47a0-9057-4ae7baa2767e",
   "metadata": {},
   "source": [
    "# Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fdb4a4-af41-4a8c-b9e5-a104a5421a8f",
   "metadata": {},
   "source": [
    "In a one-way ANOVA, you can calculate the Total Sum of Squares (SST), Explained Sum of Squares (SSE), and Residual Sum of Squares (SSR) using Python. You'll typically use libraries like NumPy and SciPy to perform these calculations. Here's how you can do it:\n",
    "\n",
    "Total Sum of Squares (SST):\n",
    "\n",
    "SST represents the total variation in the dependent variable. It is the sum of squared differences between each data point and the overall mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "271e5e5b-2723-4288-a0f0-012e562b7975",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'group1_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Create an array of data (replace with your data)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mgroup1_data\u001b[49m, group2_data, group3_data, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Calculate the overall mean\u001b[39;00m\n\u001b[1;32m      5\u001b[0m overall_mean \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(data)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'group1_data' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Create an array of data (replace with your data)\n",
    "data = np.array([group1_data, group2_data, group3_data, ...])\n",
    "# Calculate the overall mean\n",
    "overall_mean = np.mean(data)\n",
    "# Calculate the total sum of squares (SST)\n",
    "SST = np.sum((data - overall_mean) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0de206a-8697-4c73-bb05-97f408073389",
   "metadata": {},
   "source": [
    "Explained Sum of Squares (SSE):\n",
    "\n",
    "SSE represents the variation in the dependent variable explained by the differences between the group means. It is the sum of squared differences between each group mean and the overall mean, weighted by the number of observations in each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90cfa303-02e7-485c-9f4c-2858e475c0e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3240877760.py, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 15\u001b[0;36m\u001b[0m\n\u001b[0;31m    )\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Create arrays for each group's data (replace with your data)\n",
    "group1_data = np.array([value1, value2, ...])\n",
    "group2_data = np.array([value1, value2, ...])\n",
    "group3_data = np.array([value1, value2, ...])\n",
    "# Calculate the group means\n",
    "group1_mean = np.mean(group1_data)\n",
    "group2_mean = np.mean(group2_data)\n",
    "group3_mean = np.mean(group3_data)\n",
    "# ...\n",
    "# Calculate the explained sum of squares (SSE)\n",
    "SSE = (len(group1_data) * (group1_mean - overall_mean) ** 2 +\n",
    "       len(group2_data) * (group2_mean - overall_mean) ** 2 +\n",
    "       len(group3_data) * (group3_mean - overall_mean) ** 2 +\n",
    "       # ... Repeat for other groups\n",
    "       )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f78955-14f9-44e2-874b-353915e3eb49",
   "metadata": {},
   "source": [
    "Residual Sum of Squares (SSR):\n",
    "\n",
    "SSR represents the unexplained variation in the dependent variable. It is the sum of squared differences between each data point and its respective group mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc35ceb3-cef7-4e54-bc8f-0b3afc7da9a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'group1_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Calculate the residuals for each group\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m residuals_group1 \u001b[38;5;241m=\u001b[39m \u001b[43mgroup1_data\u001b[49m \u001b[38;5;241m-\u001b[39m group1_mean\n\u001b[1;32m      3\u001b[0m residuals_group2 \u001b[38;5;241m=\u001b[39m group2_data \u001b[38;5;241m-\u001b[39m group2_mean\n\u001b[1;32m      4\u001b[0m residuals_group3 \u001b[38;5;241m=\u001b[39m group3_data \u001b[38;5;241m-\u001b[39m group3_mean\n",
      "\u001b[0;31mNameError\u001b[0m: name 'group1_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Calculate the residuals for each group\n",
    "residuals_group1 = group1_data - group1_mean\n",
    "residuals_group2 = group2_data - group2_mean\n",
    "residuals_group3 = group3_data - group3_mean\n",
    "# ...\n",
    "\n",
    "# Calculate the residual sum of squares (SSR)\n",
    "SSR = np.sum(residuals_group1 ** 2) + np.sum(residuals_group2 ** 2) + np.sum(residuals_group3 ** 2) + ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dc55e5-7d1c-4ea3-858b-f984f0ea38e9",
   "metadata": {},
   "source": [
    "Once you have calculated SST, SSE, and SSR, you can use these values to perform an F-test to determine whether there are significant differences among the group means. This test will help you assess whether the independent variable (e.g., group or treatment) has a statistically significant effect on the dependent variable. You can use libraries like SciPy to perform the F-test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053f509a-2ca4-412e-9999-39c6862a15da",
   "metadata": {},
   "source": [
    "# Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b29feb-daeb-4c0d-91cd-ea7eb9037e3f",
   "metadata": {},
   "source": [
    "A5 : In a two-way ANOVA, you can calculate the main effects and interaction effects using Python with the help of libraries like NumPy and SciPy. Here's a step-by-step guide on how to do it:\n",
    "\n",
    "Let's assume you have a dataset with two categorical independent variables, Factor A (with 'a' levels) and Factor B (with 'b' levels), and a continuous dependent variable.\n",
    "\n",
    "Data Preparation:\n",
    "\n",
    "Organize your data into arrays or data structures where each row corresponds to an observation, and each column corresponds to one of the factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9485b77-082a-4037-b499-79c28b7ec7e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'level1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Create arrays for Factor A, Factor B, and the dependent variable (replace with your data)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m factor_A \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mlevel1\u001b[49m, level2, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, levela, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m])\n\u001b[1;32m      5\u001b[0m factor_B \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([level1, level2, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, levelb, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m])\n\u001b[1;32m      6\u001b[0m dependent_variable \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([value1, value2, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, valueN])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'level1' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create arrays for Factor A, Factor B, and the dependent variable (replace with your data)\n",
    "factor_A = np.array([level1, level2, ..., levela, ...])\n",
    "factor_B = np.array([level1, level2, ..., levelb, ...])\n",
    "dependent_variable = np.array([value1, value2, ..., valueN])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a514d2d-0174-47ca-896c-3eec94d78e16",
   "metadata": {},
   "source": [
    "Calculate Group Means:\n",
    "\n",
    "Calculate the means for each combination of Factor A and Factor B. These are the cell means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00c57c8b-c9b5-4297-925a-9bb32e52480a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'factor_A' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stats\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Calculate cell means using scipy's stats.binned_statistic_2d function\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m cell_means, _, _ \u001b[38;5;241m=\u001b[39m stats\u001b[38;5;241m.\u001b[39mbinned_statistic_2d(\u001b[43mfactor_A\u001b[49m, factor_B, dependent_variable, statistic\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m, bins\u001b[38;5;241m=\u001b[39m[a_levels, b_levels])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'factor_A' is not defined"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Calculate cell means using scipy's stats.binned_statistic_2d function\n",
    "cell_means, _, _ = stats.binned_statistic_2d(factor_A, factor_B, dependent_variable, statistic='mean', bins=[a_levels, b_levels])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d9d6ec-8886-463f-b053-e79132531be3",
   "metadata": {},
   "source": [
    "Calculate Marginal Means:\n",
    "    \n",
    "Calculate the marginal means for Factor A and Factor B. These are the main effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22f07cb9-1303-4959-923a-71e622ce4164",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cell_means' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Calculate the marginal means for Factor A\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m marginal_mean_A \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(\u001b[43mcell_means\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Calculate the marginal means for Factor B\u001b[39;00m\n\u001b[1;32m      5\u001b[0m marginal_mean_B \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(cell_means, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cell_means' is not defined"
     ]
    }
   ],
   "source": [
    "# Calculate the marginal means for Factor A\n",
    "marginal_mean_A = np.mean(cell_means, axis=1)\n",
    "\n",
    "# Calculate the marginal means for Factor B\n",
    "marginal_mean_B = np.mean(cell_means, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbab5b58-2e10-40bb-a0e1-a6ebd56e0506",
   "metadata": {},
   "source": [
    "Calculate Interaction Effect:\n",
    "\n",
    "Calculate the interaction effect by subtracting the marginal means from the cell means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96a27ad7-5b36-4f04-a974-bdb0483ede26",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cell_means' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Calculate the interaction effect\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m interaction_effect \u001b[38;5;241m=\u001b[39m \u001b[43mcell_means\u001b[49m \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mouter(marginal_mean_A, marginal_mean_B)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cell_means' is not defined"
     ]
    }
   ],
   "source": [
    "# Calculate the interaction effect\n",
    "interaction_effect = cell_means - np.outer(marginal_mean_A, marginal_mean_B)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86426b0-26ed-436d-afeb-db5c0d9ce532",
   "metadata": {},
   "source": [
    "Performing Hypothesis Tests:\n",
    "\n",
    "You can use hypothesis tests to determine if the main effects and interaction effect are statistically significant. For this, you would typically use an ANOVA table or statistical tests such as F-tests.\n",
    "\n",
    "Here's a simplified example that demonstrates how to calculate main effects and interaction effects using Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f43c6bdc-b876-406c-9c86-50447286f217",
   "metadata": {},
   "outputs": [
    {
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'minimum' did not contain a loop with signature matching types (dtype('<U2'), dtype('<U2')) -> None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m dependent_variable \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m14\u001b[39m])\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Calculate cell means\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m cell_means, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mstats\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinned_statistic_2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfactor_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfactor_B\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdependent_variable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatistic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Calculate marginal means for Factor A and Factor B\u001b[39;00m\n\u001b[1;32m     13\u001b[0m marginal_mean_A \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(cell_means, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/scipy/stats/_binned_statistic.py:352\u001b[0m, in \u001b[0;36mbinned_statistic_2d\u001b[0;34m(x, y, values, statistic, bins, range, expand_binnumbers)\u001b[0m\n\u001b[1;32m    349\u001b[0m     xedges \u001b[38;5;241m=\u001b[39m yedges \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(bins, \u001b[38;5;28mfloat\u001b[39m)\n\u001b[1;32m    350\u001b[0m     bins \u001b[38;5;241m=\u001b[39m [xedges, yedges]\n\u001b[0;32m--> 352\u001b[0m medians, edges, binnumbers \u001b[38;5;241m=\u001b[39m \u001b[43mbinned_statistic_dd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatistic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexpand_binnumbers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpand_binnumbers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m BinnedStatistic2dResult(medians, edges[\u001b[38;5;241m0\u001b[39m], edges[\u001b[38;5;241m1\u001b[39m], binnumbers)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/scipy/stats/_binned_statistic.py:570\u001b[0m, in \u001b[0;36mbinned_statistic_dd\u001b[0;34m(sample, values, statistic, bins, range, expand_binnumbers, binned_statistic_result)\u001b[0m\n\u001b[1;32m    567\u001b[0m     bins \u001b[38;5;241m=\u001b[39m Ndim \u001b[38;5;241m*\u001b[39m [bins]\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m binned_statistic_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 570\u001b[0m     nbin, edges, dedges \u001b[38;5;241m=\u001b[39m \u001b[43m_bin_edges\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    571\u001b[0m     binnumbers \u001b[38;5;241m=\u001b[39m _bin_numbers(sample, nbin, edges, dedges)\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/scipy/stats/_binned_statistic.py:693\u001b[0m, in \u001b[0;36m_bin_edges\u001b[0;34m(sample, bins, range)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;66;03m# Select range for each dimension\u001b[39;00m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;66;03m# Used only if number of bins is given.\u001b[39;00m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mrange\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 693\u001b[0m     smin \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39matleast_1d(np\u001b[38;5;241m.\u001b[39marray(\u001b[43msample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;28mfloat\u001b[39m))\n\u001b[1;32m    694\u001b[0m     smax \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39matleast_1d(np\u001b[38;5;241m.\u001b[39marray(sample\u001b[38;5;241m.\u001b[39mmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mfloat\u001b[39m))\n\u001b[1;32m    695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:44\u001b[0m, in \u001b[0;36m_amin\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_amin\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     43\u001b[0m           initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_minimum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mUFuncTypeError\u001b[0m: ufunc 'minimum' did not contain a loop with signature matching types (dtype('<U2'), dtype('<U2')) -> None"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Example data\n",
    "factor_A = np.array(['A1', 'A1', 'A2', 'A2', 'A3'])\n",
    "factor_B = np.array(['B1', 'B2', 'B1', 'B2', 'B1'])\n",
    "dependent_variable = np.array([10, 12, 8, 9, 14])\n",
    "\n",
    "# Calculate cell means\n",
    "cell_means, _, _ = stats.binned_statistic_2d(factor_A, factor_B, dependent_variable, statistic='mean', bins=[3, 2])\n",
    "\n",
    "# Calculate marginal means for Factor A and Factor B\n",
    "marginal_mean_A = np.mean(cell_means, axis=1)\n",
    "marginal_mean_B = np.mean(cell_means, axis=0)\n",
    "\n",
    "# Calculate interaction effect\n",
    "interaction_effect = cell_means - np.outer(marginal_mean_A, marginal_mean_B)\n",
    "\n",
    "print(\"Cell Means:\")\n",
    "print(cell_means)\n",
    "print(\"Marginal Mean for Factor A:\", marginal_mean_A)\n",
    "print(\"Marginal Mean for Factor B:\", marginal_mean_B)\n",
    "print(\"Interaction Effect:\")\n",
    "print(interaction_effect)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1474a9-446c-451e-8237-94dc5f782150",
   "metadata": {},
   "source": [
    "Remember that for hypothesis testing, you would typically perform ANOVA tests or other relevant statistical tests to assess the significance of the main effects and interaction effect. The F-statistic and p-values are often used for this purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e21d5ed-9bb7-4214-8cb3-8f193d2851a2",
   "metadata": {},
   "source": [
    "# Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02. What can you conclude about the differences between the groups, and how would you interpret these results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1b0783-874a-4a15-be1a-79bce75f380d",
   "metadata": {},
   "source": [
    "A6 : \n",
    "    \n",
    "In a one-way ANOVA, the F-statistic and its associated p-value are used to assess whether there are significant differences among the means of three or more groups. Here's how to interpret the results you provided:\n",
    "\n",
    "F-Statistic: The F-statistic is a test statistic that measures the ratio of the variance between groups (explained variance) to the variance within groups (unexplained variance). It quantifies whether the differences in group means are statistically significant.\n",
    "\n",
    "P-Value: The p-value associated with the F-statistic tells you the probability of observing the results (or more extreme results) if there were no significant differences among the groups. A small p-value indicates evidence against the null hypothesis.\n",
    "\n",
    "In your case:\n",
    "\n",
    "F-Statistic = 5.23\n",
    "\n",
    "p-Value = 0.02\n",
    "\n",
    "- Interpretation:\n",
    "\n",
    "Null Hypothesis (H0): The null hypothesis in this case is that there are no significant differences among the group means (i.e., all group means are equal).\n",
    "\n",
    "Alternative Hypothesis (Ha): The alternative hypothesis is that at least one group mean is significantly different from the others.\n",
    "\n",
    "- Interpretation:\n",
    "\n",
    "Since the p-value (0.02) is less than the significance level (commonly chosen at 0.05 or 0.01), you would reject the null hypothesis.\n",
    "\n",
    "Based on the results, you have evidence to conclude that there are statistically significant differences among the group means.\n",
    "\n",
    "However, the ANOVA test itself does not tell you which specific groups are different from each other. If you want to identify which pairs of groups have significant differences, you may need to perform post hoc tests, such as Tukey's HSD (Honestly Significant Difference) test or Bonferroni corrections.\n",
    "\n",
    "Additionally, you can calculate effect size measures (e.g., eta-squared or partial eta-squared) to quantify the practical significance or strength of the observed differences among the groups.\n",
    "\n",
    "In summary, with an F-statistic of 5.23 and a p-value of 0.02, you have evidence to conclude that there are significant differences among the groups. However, further analyses or post hoc tests may be needed to determine which specific group(s) differ from one another.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b05d54-2ce7-4493-9a6d-f14a5bad11f0",
   "metadata": {},
   "source": [
    "# Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3580b91b-39ec-47e8-8414-e7e8a86a5988",
   "metadata": {},
   "source": [
    "A7:\n",
    "    \n",
    "Handling missing data in a repeated measures ANOVA (or any statistical analysis) is crucial to ensure the validity and reliability of your results. Missing data can occur for various reasons, such as participant dropouts, equipment failures, or incomplete responses. There are several methods for dealing with missing data, each with its potential consequences. Here are common approaches and their implications:\n",
    "\n",
    "- Complete Case Analysis (Listwise Deletion):\n",
    "\n",
    "In this approach, any case (participant) with missing data on any variable is removed from the analysis.\n",
    "\n",
    "Pros:\n",
    "\n",
    "Simple and straightforward.\n",
    "\n",
    "Preserves the integrity of the dataset for analysis.\n",
    "\n",
    "Cons:\n",
    "\n",
    "Reduces the sample size, potentially leading to a loss of statistical power.\n",
    "\n",
    "May introduce bias if missing data are not completely random (i.e., if certain types of participants are more likely to have missing data).\n",
    "\n",
    "- Mean Imputation (or Single Imputation):\n",
    "\n",
    "Missing values are replaced with the mean of the observed values for that variable.\n",
    "\n",
    "Pros:\n",
    "\n",
    "Simple and does not reduce the sample size.\n",
    "\n",
    "Cons:\n",
    "\n",
    "Reduces variance, potentially underestimating standard errors.\n",
    "\n",
    "Assumes that missing data are missing completely at random (MCAR), which is often unrealistic.\n",
    "\n",
    "Can distort relationships and correlations in the data.\n",
    "\n",
    "- Linear Interpolation or Last Observation Carried Forward (LOCF):\n",
    "\n",
    "Linear interpolation estimates missing values based on adjacent time points or carries forward the last observed value.\n",
    "\n",
    "Pros:\n",
    "\n",
    "Can provide plausible estimates of missing values for time-series data.\n",
    "\n",
    "Cons:\n",
    "\n",
    "Assumes linear trends between observations, which may not be valid.\n",
    "\n",
    "LOCF can overestimate the true values, particularly if the missing data occur early in the series.\n",
    "\n",
    "- Multiple Imputation:\n",
    "\n",
    "Multiple imputation generates multiple datasets with imputed values and combines results from each dataset to account for uncertainty in imputation.\n",
    "\n",
    "Pros:\n",
    "\n",
    "Provides valid and unbiased parameter estimates.\n",
    "\n",
    "Accounts for the uncertainty associated with missing data.\n",
    "\n",
    "Cons:\n",
    "\n",
    "Requires specialized software and additional computational resources.\n",
    "\n",
    "Can be complex to implement correctly.\n",
    "\n",
    "- Model-Based Imputation:\n",
    "\n",
    "Imputation methods based on regression models or machine learning techniques to predict missing values.\n",
    "\n",
    "Pros:\n",
    "\n",
    "Can provide accurate imputations when relationships between variables are well understood.\n",
    "\n",
    "Cons:\n",
    "\n",
    "Requires knowledge and assumptions about the underlying data structure.\n",
    "\n",
    "Complex and may overfit the imputed values.\n",
    "\n",
    "The choice of method should depend on the nature of the missing data and the assumptions made about the missing data mechanism (e.g., MCAR, missing at random [MAR], or missing not at random [MNAR]). It is generally advisable to perform sensitivity analyses by using multiple imputation or different methods to assess the robustness of your results to the handling of missing data.\n",
    "\n",
    "Using inappropriate methods for handling missing data can lead to biased and unreliable results. Therefore, it is essential to carefully consider the nature of your data and the assumptions underlying your chosen imputation method. Consulting with a statistician or data analyst with expertise in missing data handling is often recommended to ensure the appropriate treatment of missing data in your repeated measures ANOVA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b51c499-9fe3-42f3-94b5-4e60a9b040e8",
   "metadata": {},
   "source": [
    "# Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b91ce45-ff77-4b27-aa87-c6a0da174226",
   "metadata": {},
   "source": [
    "A8:\n",
    "    \n",
    "Post-hoc tests are used after conducting an Analysis of Variance (ANOVA) to compare group means and identify specific pairwise differences between groups when the ANOVA indicates that there are significant differences among three or more groups. Common post-hoc tests include:\n",
    "\n",
    "- Tukey's Honestly Significant Difference (Tukey's HSD):\n",
    "\n",
    "When to Use: Tukey's HSD is a conservative test appropriate for situations where you want to control the familywise error rate (the probability of making at least one Type I error across all comparisons).\n",
    "\n",
    "Example: In a one-way ANOVA comparing the performance of four different training methods, you use Tukey's HSD to determine which specific pairs of training methods have significantly different means.\n",
    "\n",
    "- Bonferroni Correction:\n",
    "\n",
    "When to Use: Bonferroni correction is a more conservative approach that controls the Type I error rate by dividing the desired significance level (e.g., 0.05) by the number of comparisons being made.\n",
    "\n",
    "Example: When conducting multiple pairwise comparisons in a one-way ANOVA with four groups, you would use Bonferroni correction to adjust the significance level for each comparison.\n",
    "\n",
    "- Scheffé's Method:\n",
    "\n",
    "When to Use: Scheffé's method is less conservative than Tukey's HSD and Bonferroni correction. It is suitable when you have unequal sample sizes and you want to control the familywise error rate.\n",
    "\n",
    "Example: In a two-way ANOVA with unequal group sizes and multiple comparisons to assess the effect of different treatments across different levels of a second factor, Scheffé's method can be used to control the error rate.\n",
    "\n",
    "- Duncan's Multiple Range Test (MRT):\n",
    "\n",
    "When to Use: Duncan's MRT is less conservative and more powerful when you have relatively homogeneous group variances. It is less stringent in controlling Type I errors.\n",
    "\n",
    "Example: In a one-way ANOVA comparing the yields of five different crop fertilizers, Duncan's MRT can help identify which fertilizers have significantly different yields.\n",
    "\n",
    "- Holm-Bonferroni Method:\n",
    "\n",
    "When to Use: Holm-Bonferroni adjusts for multiple comparisons in a way that is less conservative than Bonferroni correction but still controls the familywise error rate.\n",
    "\n",
    "Example: In a repeated measures ANOVA comparing the effects of three different interventions at multiple time points, the Holm-Bonferroni method can be used to control for multiple comparisons.\n",
    "\n",
    "- Games-Howell Test:\n",
    "\n",
    "When to Use: The Games-Howell test is suitable when group variances are unequal and sample sizes are different. It does not assume homogeneity of variances.\n",
    "\n",
    "Example: In a one-way ANOVA comparing the performance of several different schools with varying student populations, you can use the Games-Howell test to compare schools with different sample sizes and variances.\n",
    "\n",
    "- Example Situation Requiring a Post-hoc Test:\n",
    "Suppose you are conducting a one-way ANOVA to compare the effectiveness of four different advertising strategies on product sales. The ANOVA indicates that there are significant differences among the strategies. In this scenario, you would perform a post-hoc test (e.g., Tukey's HSD, Bonferroni, or Scheffé's method) to determine which specific pairs of advertising strategies have significantly different impacts on sales. This helps you identify which strategies are more effective than others and make informed decisions for your advertising campaign."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d350808c-7a1b-41f7-81cd-9a7e5dceff22",
   "metadata": {},
   "source": [
    "# Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from 50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python to determine if there are any significant differences between the mean weight loss of the three diets. Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "953a7165-7ae0-4df8-8080-0f089ff7ef29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Statistic: 38.03703703703701\n",
      "p-value: 6.397333028465909e-06\n",
      "The p-value is less than the significance level (alpha).\n",
      "There are significant differences between the mean weight loss of the three diets.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "# Example data \n",
    "diet_A = np.array([2.1, 1.8, 2.5, 1.9, 2.3,])  # Weight loss for Diet A\n",
    "diet_B = np.array([1.5, 1.7, 1.3, 1.8, 1.4,])  # Weight loss for Diet B\n",
    "diet_C = np.array([2.8, 2.6, 2.9, 3.1, 2.7,])  # Weight loss for Diet C\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway (diet_A, diet_B, diet_C)\n",
    "# Print the results\n",
    "print(\"F-Statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "# Interpret the results\n",
    "alpha = 0.05  # Set the significance level\n",
    "if p_value < alpha:\n",
    "    print(\"The p-value is less than the significance level (alpha).\")\n",
    "    print(\"There are significant differences between the mean weight loss of the three diets.\")\n",
    "else:\n",
    "    print(\"The p-value is greater than the significance level (alpha).\")\n",
    "    print(\"There is no evidence of significant differences between the mean weight loss of the three diets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55f21f5-ac21-4117-a56a-b2d13c21f438",
   "metadata": {},
   "source": [
    "# Q10. A company wants to know if there are any significant differences in the average time it takes to complete a task using three different software programs: Program A, Program B, and Program C. They randomly assign 30 employees to one of the programs and record the time it takes each employee to complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or interaction effects between the software programs and employee experience level (novice vs. experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7db7c5f-04dd-4d65-bf3a-3c9133597686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                sum_sq    df         F    PR(>F)\n",
      "C(Software)                  30.597812   2.0  0.585784  0.558927\n",
      "C(Experience)                51.740366   1.0  1.981103  0.162964\n",
      "C(Software):C(Experience)    13.197384   2.0  0.252659  0.777321\n",
      "Residual                   2193.824194  84.0       NaN       NaN\n",
      "There is no significant main effect of Software.\n",
      "There is no significant main effect of Experience.\n",
      "There is no significant interaction effect between Software and Experience.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "# Example data\n",
    "data = pd.DataFrame({\n",
    "    'Software': ['A', 'B', 'C'] * 30,\n",
    "    'Experience': ['Novice', 'Experienced'] * 45,\n",
    "    'Time': np.random.normal(30, 5, 90)  # Random time data\n",
    "})\n",
    "# Fit the two-way ANOVA model\n",
    "formula = 'Time ~ C(Software) + C(Experience) + C(Software):C(Experience)'\n",
    "model = ols(formula, data=data).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "# Print the ANOVA table\n",
    "print(anova_table)\n",
    "# Interpret the results\n",
    "alpha = 0.05  # Set the significance level\n",
    "# Main effects of Software and Experience\n",
    "p_software = anova_table['PR(>F)']['C(Software)']\n",
    "p_experience = anova_table['PR(>F)']['C(Experience)']\n",
    "# Interaction effect\n",
    "p_interaction = anova_table['PR(>F)']['C(Software):C(Experience)']\n",
    "\n",
    "if p_software < alpha:\n",
    "    print(\"There is a significant main effect of Software.\")\n",
    "else:\n",
    "    print(\"There is no significant main effect of Software.\")\n",
    "\n",
    "if p_experience < alpha:\n",
    "    print(\"There is a significant main effect of Experience.\")\n",
    "else:\n",
    "    print(\"There is no significant main effect of Experience.\")\n",
    "\n",
    "if p_interaction < alpha:\n",
    "    print(\"There is a significant interaction effect between Software and Experience.\")\n",
    "else:\n",
    "    print(\"There is no significant interaction effect between Software and Experience.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175f14f5-f896-4a53-a322-cdb6befb84b9",
   "metadata": {},
   "source": [
    "This code will help you determine whether there are main effects or interaction effects between software programs and employee experience levels in terms of task completion time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21636a03-769b-4fd4-8c41-a82fc4b90d89",
   "metadata": {},
   "source": [
    "# Q11. An educational researcher is interested in whether a new teaching method improves student test scores. They randomly assign 100 students to either the control group (traditional teaching method) or the experimental group (new teaching method) and administer a test at the end of the semester. Conduct a two-sample t-test using Python to determine if there are any significant differences in test scores between the two groups. If the results are significant, follow up with a post-hoc test to determine which group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf3b8c94-999b-4b12-9668-7a562d42890d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-Sample T-Test Results:\n",
      "t-statistic: -2.400000000000001\n",
      "p-value: 0.0431767278278466\n",
      "The p-value is less than the significance level (alpha).\n",
      "There is a significant difference in test scores between the two groups.\n",
      "You can proceed with a post-hoc test to determine which group(s) differ significantly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "# Example data\n",
    "control_group_scores = np.array([85, 88, 92, 78, 90,])  # Test scores for control group\n",
    "experimental_group_scores = np.array([95, 92, 98, 88, 96,])  # Test scores for experimental group\n",
    "# Perform a two-sample t-test\n",
    "t_statistic, p_value = stats.ttest_ind(control_group_scores, experimental_group_scores)\n",
    "# Print the results of the t-test\n",
    "print(\"Two-Sample T-Test Results:\")\n",
    "print(\"t-statistic:\", t_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "# Set the significance level (alpha)\n",
    "alpha = 0.05\n",
    "# Interpret the t-test results\n",
    "if p_value < alpha:\n",
    "    print(\"The p-value is less than the significance level (alpha).\")\n",
    "    print(\"There is a significant difference in test scores between the two groups.\")\n",
    "    print(\"You can proceed with a post-hoc test to determine which group(s) differ significantly.\")\n",
    "else:\n",
    "    print(\"The p-value is greater than or equal to the significance level (alpha).\")\n",
    "    print(\"There is no significant difference in test scores between the two groups.\")\n",
    "# If the t-test is significant, you can proceed with post-hoc tests (e.g., Tukey's HSD or Bonferroni) to identify specific group differences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8287ec9-a3d3-4e18-9d3d-056bba14809e",
   "metadata": {},
   "source": [
    "# Q12. A researcher wants to know if there are any significant differences in the average daily sales of three retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store on those days. Conduct a repeated measures ANOVA using Python to determine if there are any significant differences in sales between the three stores. If the results are significant, follow up with a post- hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e888f522-3f01-480b-b2e7-f1729ff576ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-Way ANOVA Results:\n",
      "F-Statistic: 46.936758893280626\n",
      "p-value: 1.7327070140008526e-05\n",
      "The p-value is less than the significance level (alpha).\n",
      "There are significant differences in daily sales between the three stores.\n",
      "You can proceed with post-hoc tests to determine which store(s) differ significantly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "# Example data \n",
    "store_A_sales = np.array([1000, 950, 1100, 1050])  # Sales data for Store A\n",
    "store_B_sales = np.array([900, 850, 920, 930])    # Sales data for Store B\n",
    "store_C_sales = np.array([1200, 1250, 1180, 1220])  # Sales data for Store C\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(store_A_sales, store_B_sales, store_C_sales)\n",
    "# Print the results of the one-way ANOVA\n",
    "print(\"One-Way ANOVA Results:\")\n",
    "print(\"F-Statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "# Set the significance level (alpha)\n",
    "alpha = 0.05\n",
    "# Interpret the one-way ANOVA results\n",
    "if p_value < alpha:\n",
    "    print(\"The p-value is less than the significance level (alpha).\")\n",
    "    print(\"There are significant differences in daily sales between the three stores.\")\n",
    "    print(\"You can proceed with post-hoc tests to determine which store(s) differ significantly.\")\n",
    "else:\n",
    "    print(\"The p-value is greater than or equal to the significance level (alpha).\")\n",
    "    print(\"There is no significant difference in daily sales between the three stores.\")\n",
    "# If the one-way ANOVA is significant, you can proceed with post-hoc tests (e.g., Tukey's HSD or Bonferroni) to identify specific store differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7421ee-aff6-43ca-9e62-c60e4651bd4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
